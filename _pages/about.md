---
layout: about
title: About
permalink: /
subtitle: LLM Engineer | ex Moreh, Menlo Research, Viettel

profile:
  align: right
  image: charles.png
  image_circular: false # crops the image to make it circular
  address: >
   

news: true  # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

Hi! I'm Charles; interested in LLM Systems, with experience spanning AI research (Machine Learning, Computer Vision, Speech) to applications (Recommendation Systems, LLMs), and across the stack - from low-level GPU kernel optimization to high-level system design, training to serving.

**Industry:**

* Implemented a [pure HIP C++ of OpenAI’s GPT-OSS from scratch](https://github.com/tuanlda78202/gpt-oss-amd), optimizing model loading, multi-streaming, multi-GPU communication, CPU-GPU-SRAM memory access, FlashAttention 2, matrix-core GEMM, MoE load balancing, etc. Achieved 30k TPS (20B) and 10k TPS (120B) on a single node with 8× AMD MI250x GPUs.

* Architected [Leo](https://github.com/tuanlda78202/leo) - an end-to-end LLMOps system for a personal AI assistant, unifying data, feature, training, inference, and observability layers under clean architecture principles; built offline pipelines for data retrieval, ETL, SFT, and RAG indexing managed by an orchestrator, and designed an agentic RAG-based online system with API integration, MCP support, contextual retrieval, and prompt caching/monitoring.

* Developed a multimodal, multi-agent conversational recommendation system with vision and speech-to-speech interaction; integrated AdaptiveICL, synthetic data generation, retrieval-ranking pipelines with API communication between application and infrastructure layers and **achieved Top 1 in track DSAI at Viettel Digital Talent 2024**.

**Research:**

* Researched [Speechless](https://arxiv.org/abs/2505.17417) model, aiming to generate synthetic semantic audio representations from multimodal inputs, trained on semantic tokens generated by [Ichigo Whisper](https://huggingface.co/Menlo/Ichigo-whisper-v0.1); published a paper **accepted at Interspeech 2025 (Rank A)**.

* Developed ["Efficient Continual Detection Transformer"](https://www.linkedin.com/feed/update/urn:li:activity:7209885129920368640), leveraging pseudo-labeling, knowledge distillation, and LoRA; achieved high performance with only 3% trainable parameters compared to the RT-DETR on COCO.

**Community:**

* Released and maintained open-source projects for developers, including [gpt-oss-amd (150 ⭐️)](https://github.com/tuanlda78202/gpt-oss-amd), [nvims (100 ⭐️)](https://github.com/tuanlda78202/nvims), and [leo](https://github.com/tuanlda78202/leo); contributed to leading projects like [Ichigo (2.4k ⭐️)](https://github.com/menloresearch/ichigo) and [WhisperSpeech (4.5k ⭐️)](https://github.com/WhisperSpeech/WhisperSpeech).

* Organized multiple technical events for the developer community, such as VinAI Day, Google I/O Extended, Google DevFest, International Women’s Day x Flutter Forward Extended, and Google Build with AI; [spoke at Google DevFest 2022](https://www.facebook.com/GDGhanoi/photos/a.295913770557546/2473122272836674) on “Detecting Cheating in Examinations”; [certified by Google’s Global Headquarters](https://drive.google.com/file/d/1wRyXDH3vbakH1dkueh88lQVuRn85nwjU/view?usp=sharing).

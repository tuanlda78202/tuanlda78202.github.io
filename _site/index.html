<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Tuan Le Duc Anh</title>
    <meta name="author" content="Tuan  Le Duc Anh" />
    <meta name="description" content="My personal website.
" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img//assets/img/favicon.ico"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">Blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">CV</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
           Tuan Le Duc Anh
          </h1>
          <p class="desc">Ph.D. Student at <a href="https://stat.utexas.edu/" target="_blank" rel="noopener noreferrer">Department of Statistics and Data Sciences</a>, <a href="https://www.utexas.edu/" target="_blank" rel="noopener noreferrer">University of Texas at Austin</a></p>
        </header>

        <article>
          <div class="profile float-right">

              <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/khai2-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/khai2-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/khai2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/khai2.png" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="khai2.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

            <div class="address">
              
            </div>
          </div>

          <div class="clearfix">
            <p>Hi! I’m Khai, a second-year Ph.D. student at <a href="https://stat.utexas.edu/" target="_blank" rel="noopener noreferrer">Department of Statistics and Data Sciences</a>, <a href="https://www.utexas.edu/" target="_blank" rel="noopener noreferrer">University of Texas at Austin</a>, advised by Professor <a href="https://nhatptnk8912.github.io/" target="_blank" rel="noopener noreferrer">Nhat Ho</a>. I graduated from  <a href="https://soict.hust.edu.vn/" target="_blank" rel="noopener noreferrer">Hanoi University of Science and Technology</a> with an excellent Computer Science Bachelor’s degree.
Before joining UT Austin, I was an AI Research Resident at <a href="http://www.vinai.io" target="_blank" rel="noopener noreferrer">VinAI Research, Vietnam</a> under the supervision of <a href="https://sites.google.com/site/buihhung/" target="_blank" rel="noopener noreferrer">Dr. Hung Bui</a>.</p>

<p><strong>Research:</strong> My current works are making <a href="https://en.wikipedia.org/wiki/Transportation_theory_(mathematics)" target="_blank" rel="noopener noreferrer">Optimal Transport</a> scalable (low computational complexity, low memory complexity, low sample complexity) in Machine Learning. In particular, I investigate new dimension reduction methods via projections (sliced Wasserstein) and new sub-sampling methods (mini-batch Optimal Transport). On the application side, I am interested in utilizing Optimal Transport to improve generative models, Bayesian inference, domain adaptation, and other tasks that need to deal with probability measures. I am also interested in designing efficient <a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" rel="noopener noreferrer">Transformer</a> architectures.</p>

          </div>

<!--          -->
<!--          &lt;!&ndash; News &ndash;&gt;-->
<!--          
          <div class="news">
            <h2>News</h2>
            <div class="table-responsive" >
              <table class="table table-sm table-borderless">
               
                <tr>
                  <th scope="row">Jan 15, 2016</th>
                  <td>
                    A simple inline announcement with Markdown emoji! :sparkles: :smile:
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Nov 8, 2015</th>
                  <td>
                    <a class="news-title" href="/news/announcement_2/">A long announcement with details</a> 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Oct 23, 2015</th>
                  <td>
                    A simple inline announcement.
 
                  </td>
                </tr> 
              </table>
            </div> 
          </div>
-->
<!---->
          <!-- Selected papers -->
          <div class="publications">
            <h2>Selected Publications <a href="https://khainb.github.io/publications/" target="_blank" rel="noopener noreferrer">[Full List] </a>
</h2>
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#0048BA"><a href="https://neurips.cc/" target="_blank" rel="noopener noreferrer">NeurIPS</a></abbr></div>

        <!-- Entry bib key -->
        <div id="nguyen2022revisiting" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Revisiting Sliced Wasserstein on Images: From Vectorization to Convolution</div>
          <!-- Author -->
          <div class="author">
          

          Khai Nguyen, and <a href="https://nhatptnk8912.github.io/" target="_blank" rel="noopener noreferrer">Nhat Ho</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Advances in Neural Information Processing Systems</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/pdf/2204.01188.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/UT-Austin-Data-Science-Group/CSW" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The conventional sliced Wasserstein is defined between two probability measures that have realizations as vectors. When comparing two probability measures over images, practitioners first need to vectorize images and then project them to one-dimensional space by using matrix multiplication between the sample matrix and the projection matrix. After that, the sliced Wasserstein is evaluated by averaging the two corresponding one-dimensional projected probability measures. However, this approach has two limitations. The first limitation is that the spatial structure of images is not captured efficiently by the vectorization step; therefore, the later slicing process becomes harder to gather the discrepancy information. The second limitation is memory inefficiency since each slicing direction is a vector that has the same dimension as the images. To address these limitations, we propose novel slicing methods for sliced Wasserstein between probability measures over images that are based on the convolution operators. We derive convolution sliced Wasserstein (CSW) and its variants via incorporating stride, dilation, and non-linear activation function into the convolution operators. We investigate the metricity of CSW as well as its sample complexity, its computational complexity, and its connection to conventional sliced Wasserstein distances. Finally, we demonstrate the favorable performance of CSW over the conventional sliced Wasserstein in comparing probability measures over images and in training deep generative modeling on images.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#0048BA"><a href="https://neurips.cc/" target="_blank" rel="noopener noreferrer">NeurIPS</a></abbr></div>

        <!-- Entry bib key -->
        <div id="nguyen2022amortized" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Amortized Projection Optimization for Sliced Wasserstein Generative Models</div>
          <!-- Author -->
          <div class="author">
          

          Khai Nguyen, and <a href="https://nhatptnk8912.github.io/" target="_blank" rel="noopener noreferrer">Nhat Ho</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Advances in Neural Information Processing Systems</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/pdf/2203.13417.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/UT-Austin-Data-Science-Group/AmortizedSW" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The conventional sliced Wasserstein is defined between two probability measures that have realizations as vectors. When comparing two probability measures over images, practitioners first need to vectorize images and then project them to one-dimensional space by using matrix multiplication between the sample matrix and the projection matrix. After that, the sliced Wasserstein is evaluated by averaging the two corresponding one-dimensional projected probability measures. However, this approach has two limitations. The first limitation is that the spatial structure of images is not captured efficiently by the vectorization step; therefore, the later slicing process becomes harder to gather the discrepancy information. The second limitation is memory inefficiency since each slicing direction is a vector that has the same dimension as the images. To address these limitations, we propose novel slicing methods for sliced Wasserstein between probability measures over images that are based on the convolution operators. We derive convolution sliced Wasserstein (CSW) and its variants via incorporating stride, dilation, and non-linear activation function into the convolution operators. We investigate the metricity of CSW as well as its sample complexity, its computational complexity, and its connection to conventional sliced Wasserstein distances. Finally, we demonstrate the favorable performance of CSW over the conventional sliced Wasserstein in comparing probability measures over images and in training deep generative modeling on images.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#848482"><a href="https://icml.cc/" target="_blank" rel="noopener noreferrer">ICML</a></abbr></div>

        <!-- Entry bib key -->
        <div id="pmlr-v162-nguyen22e" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Improving Mini-batch Optimal Transport via Partial Transportation</div>
          <!-- Author -->
          <div class="author">
          

          Khai Nguyen, Dang Nguyen, The-Anh Vu Le, and
            <span class="more-authors" title="click to view 2 more authors" onclick="
                  var element = $(this);
                  element.attr('title', '');
                  var more_authors_text = element.text() == '2 more authors' ? 'Tung Pham, Nhat Ho' : '2 more authors';
                  var cursorPosition = 0;
                  var textAdder = setInterval(function(){
                    element.text(more_authors_text.substring(0, cursorPosition + 1));
                    if (++cursorPosition == more_authors_text.length){
                      clearInterval(textAdder);
                    }
                }, '10');
                ">2 more authors</span>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 39th International Conference on Machine Learning</em> 17–23 jul 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://proceedings.mlr.press/v162/nguyen22e/nguyen22e.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/UT-Austin-Data-Science-Group/Mini-batch-OT" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Mini-batch optimal transport (m-OT) has been widely used recently to deal with the memory issue of OT in large-scale applications. Despite their practicality, m-OT suffers from misspecified mappings, namely, mappings that are optimal on the mini-batch level but are partially wrong in the comparison with the optimal transportation plan between the original measures. Motivated by the misspecified mappings issue, we propose a novel mini-batch method by using partial optimal transport (POT) between mini-batch empirical measures, which we refer to as mini-batch partial optimal transport (m-POT). Leveraging the insight from the partial transportation, we explain the source of misspecified mappings from the m-OT and motivate why limiting the amount of transported masses among mini-batches via POT can alleviate the incorrect mappings. Finally, we carry out extensive experiments on various applications such as deep domain adaptation, partial domain adaptation, deep generative model, color transfer, and gradient flow to demonstrate the favorable performance of m-POT compared to current mini-batch methods.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#848482"><a href="https://icml.cc/" target="_blank" rel="noopener noreferrer">ICML</a></abbr></div>

        <!-- Entry bib key -->
        <div id="pmlr-v162-nguyen22d" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">On Transportation of Mini-batches: A Hierarchical Approach</div>
          <!-- Author -->
          <div class="author">
          

          Khai Nguyen, Dang Nguyen, Quoc Nguyen, and
            <span class="more-authors" title="click to view 5 more authors" onclick="
                  var element = $(this);
                  element.attr('title', '');
                  var more_authors_text = element.text() == '5 more authors' ? 'Tung Pham, Hung Bui, Dinh Phung, Trung Le, Nhat Ho' : '5 more authors';
                  var cursorPosition = 0;
                  var textAdder = setInterval(function(){
                    element.text(more_authors_text.substring(0, cursorPosition + 1));
                    if (++cursorPosition == more_authors_text.length){
                      clearInterval(textAdder);
                    }
                }, '10');
                ">5 more authors</span>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 39th International Conference on Machine Learning</em> 17–23 jul 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://proceedings.mlr.press/v162/nguyen22d/nguyen22d.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/UT-Austin-Data-Science-Group/Mini-batch-OT" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Mini-batch optimal transport (m-OT) has been successfully used in practical applications that involve probability measures with a very high number of supports. The m-OT solves several smaller optimal transport problems and then returns the average of their costs and transportation plans. Despite its scalability advantage, the m-OT does not consider the relationship between mini-batches which leads to undesirable estimation. Moreover, the m-OT does not approximate a proper metric between probability measures since the identity property is not satisfied. To address these problems, we propose a novel mini-batch scheme for optimal transport, named Batch of Mini-batches Optimal Transport (BoMb-OT), that finds the optimal coupling between mini-batches and it can be seen as an approximation to a well-defined distance on the space of probability measures. Furthermore, we show that the m-OT is a limit of the entropic regularized version of the BoMb-OT when the regularized parameter goes to infinity. Finally, we carry out experiments on various applications including deep generative models, deep domain adaptation, approximate Bayesian computation, color transfer, and gradient flow to show that the BoMb-OT can be widely applied and performs well in various applications.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#B284BE"><a href="https://iclr.cc/" target="_blank" rel="noopener noreferrer">ICLR</a></abbr></div>

        <!-- Entry bib key -->
        <div id="nguyen2021distributional" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Distributional Sliced-Wasserstein and Applications to Generative Modeling</div>
          <!-- Author -->
          <div class="author">
          

          Khai Nguyen, <a href="https://nhatptnk8912.github.io/" target="_blank" rel="noopener noreferrer">Nhat Ho</a>, Tung Pham, and
            <span class="more-authors" title="click to view 1 more author" onclick="
                  var element = $(this);
                  element.attr('title', '');
                  var more_authors_text = element.text() == '1 more author' ? 'Hung Bui' : '1 more author';
                  var cursorPosition = 0;
                  var textAdder = setInterval(function(){
                    element.text(more_authors_text.substring(0, cursorPosition + 1));
                    if (++cursorPosition == more_authors_text.length){
                      clearInterval(textAdder);
                    }
                }, '10');
                ">1 more author</span>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Learning Representations</em> 17–23 jul 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openreview.net/pdf?id=QYjO70ACDK" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/VinAIResearch/DSW" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Sliced-Wasserstein distance (SW) and its variant, Max Sliced-Wasserstein distance (Max-SW), have been used widely in the recent years due to their fast computation and scalability even when the probability measures lie in a very high dimensional space. However, SW requires many unnecessary projection samples to approximate its value while Max-SW only uses the most important projection, which ignores the information of other useful directions. In order to account for these weaknesses, we propose a novel distance, named Distributional Sliced-Wasserstein distance (DSW), that finds an optimal distribution over projections that can balance between exploring distinctive projecting directions and the informativeness of projections themselves. We show that the DSW is a generalization of Max-SW, and it can be computed efficiently by searching for the optimal push-forward measure over a set of probability measures over the unit sphere satisfying certain regularizing constraints that favor distinct directions. Finally, we conduct extensive experiments with large-scale datasets to demonstrate the favorable performances of the proposed distances over the previous sliced-based distances in generative modeling applications.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#B284BE"><a href="https://iclr.cc/" target="_blank" rel="noopener noreferrer">ICLR</a></abbr></div>

        <!-- Entry bib key -->
        <div id="nguyen2021improving" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Improving Relational Regularized Autoencoders with Spherical Sliced Fused Gromov Wasserstein</div>
          <!-- Author -->
          <div class="author">
          

          Khai Nguyen, Son Nguyen, <a href="https://nhatptnk8912.github.io/" target="_blank" rel="noopener noreferrer">Nhat Ho</a>, and
            <span class="more-authors" title="click to view 2 more authors" onclick="
                  var element = $(this);
                  element.attr('title', '');
                  var more_authors_text = element.text() == '2 more authors' ? 'Tung Pham, Hung Bui' : '2 more authors';
                  var cursorPosition = 0;
                  var textAdder = setInterval(function(){
                    element.text(more_authors_text.substring(0, cursorPosition + 1));
                    if (++cursorPosition == more_authors_text.length){
                      clearInterval(textAdder);
                    }
                }, '10');
                ">2 more authors</span>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Learning Representations</em> 17–23 jul 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openreview.net/pdf?id=DiQD7FWL233" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Relational regularized autoencoder (RAE) is a framework to learn the distribution of data by minimizing a reconstruction loss together with a relational regularization on the prior of latent space. A recent attempt to reduce the inner discrepancy between the prior and aggregated posterior distributions is to incorporate sliced fused Gromov-Wasserstein (SFG) between these distributions. That approach has a weakness since it treats every slicing direction similarly, meanwhile several directions are not useful for the discriminative task. To improve the discrepancy and consequently the relational regularization, we propose a new relational discrepancy, named spherical sliced fused Gromov Wasserstein (SSFG), that can find an important area of projections characterized by a von Mises-Fisher distribution. Then, we introduce two variants of SSFG to improve its performance. The first variant, named mixture spherical sliced fused Gromov Wasserstein (MSSFG), replaces the vMF distribution by a mixture of von Mises-Fisher distributions to capture multiple important areas of directions that are far from each other. The second variant, named power spherical sliced fused Gromov Wasserstein (PSSFG), replaces the vMF distribution by a power spherical distribution to improve the sampling time of the vMF distribution in high dimension settings. We then apply the new discrepancies to the RAE framework to achieve its new variants. Finally, we conduct extensive experiments to show that the new autoencoders have favorable performance in learning latent manifold structure, image generation, and reconstruction.</p>
          </div>
        </div>
      </div>
</li>
</ol>
          </div>

           <!-- Selected papers -->
          <div class="publications">
            <h2>Selected Preprints <a href="https://khainb.github.io/publications/" target="_blank" rel="noopener noreferrer">[Full List]</a>
</h2>
            <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Preprint</abbr></div>

        <!-- Entry bib key -->
        <div id="nguyen2022hsw" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Hierarchical Sliced Wasserstein Distance</div>
          <!-- Author -->
          <div class="author">
          

          Khai Nguyen, Tongzheng Ren, Huy Nguyen, and
            <span class="more-authors" title="click to view 3 more authors" onclick="
                  var element = $(this);
                  element.attr('title', '');
                  var more_authors_text = element.text() == '3 more authors' ? 'Litu Rout, Tan Nguyen, Nhat Ho' : '3 more authors';
                  var cursorPosition = 0;
                  var textAdder = setInterval(function(){
                    element.text(more_authors_text.substring(0, cursorPosition + 1));
                    if (++cursorPosition == more_authors_text.length){
                      clearInterval(textAdder);
                    }
                }, '10');
                ">3 more authors</span>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>arXiv preprint arXiv:2209.13570</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/pdf/2209.13570.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/UT-Austin-Data-Science-Group/HSW" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Sliced Wasserstein (SW) distance has been widely used in different application scenarios since it can be scaled to a large number of supports without suffering from the curse of dimensionality. The value of sliced Wasserstein distance is the average of transportation cost between one-dimensional representations (projections) of original measures that are obtained by Radon Transform (RT). Despite its efficiency in the number of supports, estimating the sliced Wasserstein requires a relatively large number of projections in high-dimensional settings. Therefore, for applications where the number of supports is relatively small compared with the dimension, e.g., several deep learning applications where the mini-batch approaches are utilized, the complexities from matrix multiplication of Radon Transform become the main computational bottleneck. To address this issue, we propose to derive projections by linearly and randomly combining a smaller number of projections which are named bottleneck projections. We explain the usage of these projections by introducing Hierarchical Radon Transform (HRT) which is constructed by applying Radon Transform variants recursively. We then formulate the approach into a new metric between measures, named Hierarchical Sliced Wasserstein (HSW) distance. By proving the injectivity of HRT, we derive the metricity of HSW. Moreover, we investigate the theoretical properties of HSW including its connection to SW variants and its computational and sample complexities. Finally, we compare the computational cost and generative quality of HSW with the conventional SW on the task of deep generative modeling using various benchmark datasets including CIFAR10, CelebA, and Tiny ImageNet.</p>
          </div>
        </div>
      </div>
</li></ol>
          </div>

          <!-- Social -->
          <div class="social">
            <div class="contact-icons">
            <a href="mailto:%74%75%61%6E%6C%65%64%75%63%61%6E%68%37%38%32%30%32@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=im5fNaQAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>
            <a href="https://www.researchgate.net/profile/Khai-Nguyen-37/" title="ResearchGate" target="_blank" rel="noopener noreferrer"><i class="ai ai-researchgate"></i></a>
            <a href="https://github.com/tuanlda78202" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/tuanlda78202" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>
            <a href="https://twitter.com/tuanlda78202" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>
            

            </div>

            <div class="contact-note">
              You can even add a little note about which of these is the best way to reach you.

            </div>
            
          </div>
        </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Tuan  Le Duc Anh. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>
